{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CICIDS\n",
    "\n",
    "### **accelerated_random_forest.ipynb**\n",
    "\n",
    "The CICIDS2017 dataset is a comprehensive dataset for network intrusion detection, created by the Canadian Institute for Cybersecurity. It includes a diverse set of attack scenarios and normal traffic, making it suitable for training and evaluating intrusion detection systems.\n",
    "\n",
    "The dataset includes various types of attacks such as Brute Force, Heartbleed, Botnet, DoS (Denial of Service), DDoS (Distributed Denial of Service), Web attacks, and Infiltration of the network from inside.\n",
    "\n",
    "**This notebook demonstrates how to accelerate Random Forest training using cuML's Random Forest implementation, and using Optuna for hyperparameter optimization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"random_forest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read data and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "df_train = cudf.read_csv(\"../data/concatenated/concat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing whitespaces from column names\n",
    "df_train.columns = df_train.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset=[\"Flow Bytes/s\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf. values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "print(\"Number of NaNs in the dataset: \", df_train.isna().sum().sum())\n",
    "df_train = df_train.dropna()\n",
    "print(\"Number of NaNs in the dataset after dropping: \", df_train.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Normalise numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all numerical columns\n",
    "numerical_columns = df_train.select_dtypes(include=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.preprocessing import MinMaxScaler # cuML's MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_train[numerical_columns] = scaler.fit_transform(df_train[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Map Labels to Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_mapping = {\n",
    "\t\"BENIGN\": 0,\n",
    "\t\"DoS Hulk\": 1,\n",
    "\t\"PortScan\": 2,\n",
    "\t\"DDoS\": 3,\n",
    "\t\"DoS GoldenEye\": 4,\n",
    "\t\"FTP-Patator\": 5,\n",
    "\t\"SSH-Patator\": 6,\n",
    "\t\"DoS slowloris\": 7,\n",
    "\t\"DoS Slowhttptest\": 8,\n",
    "\t\"Bot\": 9,\n",
    "\t\"Web Attack � Brute Force\": 10,\n",
    "\t\"Web Attack � XSS\": 11,\n",
    "\t\"Infiltration\": 12,\n",
    "\t\"Web Attack � Sql Injection\": 13,\n",
    "\t\"Heartbleed\": 14,\n",
    "}\n",
    "\n",
    "df_train[\"Label\"] = df_train[\"Label\"].map(attack_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all nan values\n",
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=\"Label\")\n",
    "y = df_train[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Null values in X: \", X.isna().sum().sum())\n",
    "print(\"Null values in y: \", y.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.model_selection import train_test_split # cuML's train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Apply SMOTE to balance the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 1. Undersample the majority class\n",
    "undersampling_strategy = {\n",
    "    0: 1000,\n",
    "    1: 1000,\n",
    "    2: 1000,\n",
    "    3: 1000,\n",
    "    4: 1000,\n",
    "    5: 1000,\n",
    "    6: 1000,\n",
    "    7: 1000,\n",
    "    8: 1000,\n",
    "    9: 1000,\n",
    "\t10: 1000,\n",
    "}\n",
    "rus = RandomUnderSampler(random_state=42, sampling_strategy=undersampling_strategy)\n",
    "X_train_undersampled, y_train_undersampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Oversample the minority class\n",
    "smote = SMOTE(random_state=42, sampling_strategy=\"auto\")\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_undersampled, y_train_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution after SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"Class distribution before SMOTE: {Counter(y_train)}\")\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_train_balanced)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Find best hyperparameters using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "import optuna\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.metrics import accuracy_score, f1_score, classification_report\n",
    "from cuml.model_selection import train_test_split\n",
    "from cuml.preprocessing import RandomUnderSampler # cuML's RandomUnderSampler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an objective function for Optuna to optimize\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 300, step=50)\n",
    "    max_depth = trial.suggest_categorical(\"max_depth\", [None, 10, 20, 30, 40])\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10, step=1)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4, step=1)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"])\n",
    "    bootstrap = trial.suggest_categorical(\"bootstrap\", [True, False])\n",
    "\n",
    "    # Create the cuML RandomForestClassifier\n",
    "    rf = cuRF(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        bootstrap=bootstrap,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    # Predict and evaluate the model\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print the best hyperparameters and accuracy\n",
    "print(\"Best hyperparameters found: \", study.best_params)\n",
    "print(\"Best accuracy found: \", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Training the final model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "rf_final = cuRF(\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    max_depth=best_params[\"max_depth\"],\n",
    "    min_samples_split=best_params[\"min_samples_split\"],\n",
    "    min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "    max_features=best_params[\"max_features\"],\n",
    "    bootstrap=best_params[\"bootstrap\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample target for balancing\n",
    "SAMPLE_TARGET = 1000\n",
    "\n",
    "# Define undersampling strategy (using cuML's RandomUnderSampler)\n",
    "undersampling_strategy_test_set = {\n",
    "    0: SAMPLE_TARGET if y_test.value_counts().get(0) > SAMPLE_TARGET else y_test.value_counts().get(0),  # BENIGN\n",
    "    1: SAMPLE_TARGET if y_test.value_counts().get(1) > SAMPLE_TARGET else y_test.value_counts().get(1),  # DoS Hulk\n",
    "    2: SAMPLE_TARGET if y_test.value_counts().get(2) > SAMPLE_TARGET else y_test.value_counts().get(2),  # PortScan\n",
    "    3: SAMPLE_TARGET if y_test.value_counts().get(3) > SAMPLE_TARGET else y_test.value_counts().get(3),  # DDoS\n",
    "    4: SAMPLE_TARGET if y_test.value_counts().get(4) > SAMPLE_TARGET else y_test.value_counts().get(4),  # DoS GoldenEye\n",
    "    5: SAMPLE_TARGET if y_test.value_counts().get(5) > SAMPLE_TARGET else y_test.value_counts().get(5),  # FTP-Patator\n",
    "    6: SAMPLE_TARGET if y_test.value_counts().get(6) > SAMPLE_TARGET else y_test.value_counts().get(6),  # SSH-Patator\n",
    "    7: SAMPLE_TARGET if y_test.value_counts().get(7) > SAMPLE_TARGET else y_test.value_counts().get(7),  # DoS slowloris\n",
    "    8: SAMPLE_TARGET if y_test.value_counts().get(8) > SAMPLE_TARGET else y_test.value_counts().get(8),  # DoS Slowhttptest\n",
    "    9: SAMPLE_TARGET if y_test.value_counts().get(9) > SAMPLE_TARGET else y_test.value_counts().get(9),  # Bot\n",
    "    10: SAMPLE_TARGET if y_test.value_counts().get(10) > SAMPLE_TARGET else y_test.value_counts().get(10),  # Web Attack - Brute Force\n",
    "    11: SAMPLE_TARGET if y_test.value_counts().get(11) > SAMPLE_TARGET else y_test.value_counts().get(11),  # Web Attack - XSS\n",
    "    12: SAMPLE_TARGET if y_test.value_counts().get(12) > SAMPLE_TARGET else y_test.value_counts().get(12),  # Infiltration\n",
    "    13: SAMPLE_TARGET if y_test.value_counts().get(13) > SAMPLE_TARGET else y_test.value_counts().get(13),  # Web Attack - SQL Injection\n",
    "    14: SAMPLE_TARGET if y_test.value_counts().get(14) > SAMPLE_TARGET else y_test.value_counts().get(14),  # Heartbleed\n",
    "}\n",
    "\n",
    "# Use cuML's RandomUnderSampler\n",
    "rus_test = RandomUnderSampler(random_state=42, sampling_strategy=undersampling_strategy_test_set)\n",
    "\n",
    "# Balance the test set using cuML\n",
    "X_test_balanced, y_test_balanced = rus_test.fit_resample(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation with cuML\n",
    "y_pref_final = rf_final.predict(X_test_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_balanced, y_pref_final)\n",
    "f1 = f1_score(y_test_balanced, y_pref_final, average=\"weighted\")\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_balanced, y_pred_final, target_names=attack_mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Previous results:**\n",
    "\n",
    "| Metric             | Previous    | Current     | improvement?                           |\n",
    "| ------------------ | ----------- | ----------- | -------------------------------------- |\n",
    "| Accuracy           | 0.95        | 0.98        | <span style=\"color:#20ff20;\">yes</span>|\n",
    "| MA Range           | 0.95 - 0.95 | 0.89 - 0.90 | <span style=\"color:#ff4040;\">no</span> |\n",
    "| Precision range    | 0.66 - 1.00 | 0.36 - 1.00 | <span style=\"color:#ff4040;\">no</span> |\n",
    "| Recall range       | 0.57 - 1.00 | 0.55 - 1.00 | <span style=\"color:#ff4040;\">no</span> |\n",
    "| F1 range           | 0.63 - 1.00 | 0.43 - 1.00 | <span style=\"color:#ff4040;\">no</span> |\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
